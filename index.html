<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Shehreen Azad</title>

    <meta name="author" content="Shehreen Azad">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Shehreen Azad
                </p>
                <p>
                  I am a fourth year PhD student at <a href="https://www.crcv.ucf.edu">Center for Research in Computer Vision (CRCV)</a>, University of Central Florida (UCF), under the supervision of <a href="https://www.crcv.ucf.edu/person/rawat/" style="font-size:15px">Dr Yogesh Rawat</a>. </p>

                  <p style="font-size:15px">
                  I have a broad interest in deep learning and computer vision. My research mainly focuses on <strong>long-form video</strong> understanding and <strong>multimodal reasoning.</strong></p>
                 
                  <p style="color:red;"><b> Currently looking for internship positions for Summer'26! Feel free to drop me an email. </b></p>
                
                </p>
                <p style="text-align:center">
                  <a href="mailto:shehreen.azad@ucf.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=2SqIiLwAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://drive.google.com/file/d/1qvj7svGMu5mtkWekLH5W8qjj15GYi1pN/view?usp=share_link">Resume</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/shehreen-azad-89b1bb26a/">LinkedIn</a> &nbsp;/&nbsp;
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/profile_img.jpg"><img style="width:100%;max-width:100%;" alt="profile photo" src="images/profile_img.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">

		        <h2>Updates</h2>
                  <p>
                    <span style="font-family: 'Courier New', Courier, monospace; color: #696969;">&nbsp;<i class="fa fa-share-alt" style="font-size:12px"></i> Aug'25:</span> <strong>Broadening Participation Award</strong> to attend ICCV 2025. <br>
                    <span style="font-family: 'Courier New', Courier, monospace; color: #696969;">&nbsp;<i class="fa fa-share-alt" style="font-size:12px"></i> Jun'25:</span> <strong>DisenQ (Fist-author paper)</strong> got accepted in ICCV 2025 as Highlight. ⭐️ <br>

                    <span style="font-family: 'Courier New', Courier, monospace; color: #696969;">&nbsp;<i class="fa fa-share-alt" style="font-size:12px"></i> Mar'25:</span> <strong> Depth and Height Perception Benchmark (First-author paper)</strong> got accepted in CVPR MMFM Workshop 2025. <br>
                    <span style="font-family: 'Courier New', Courier, monospace; color: #696969;">&nbsp;<i class="fa fa-share-alt" style="font-size:12px"></i> Feb'25:</span> <strong>HierarQ (First-author paper)</strong> got accepted in CVPR'25. ⭐️ <br>

                    <span style="font-family: 'Courier New', Courier, monospace; color: #696969;">&nbsp;<i class="fa fa-share-alt" style="font-size:12px"></i> Mar'24:</span> <strong> Distribution Shift Benchmark </strong> got accepted in CVPR MMFM Workshop 2024. <br>
                    <span style="font-family: 'Courier New', Courier, monospace; color: #696969;">&nbsp;<i class="fa fa-share-alt" style="font-size:12px"></i> Mar'24:</span> <strong> Compositional Reasoning Benchmark </strong> got accepted in CVPR MMFM Workshop 2024. <br>
                    <span style="font-family: 'Courier New', Courier, monospace; color: #696969;">&nbsp;<i class="fa fa-share-alt" style="font-size:12px"></i> Feb'24:</span> <strong>Activity-Biometrics (First-author paper)</strong> got accepted in CVPR'24. ⭐️ <br>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Publications</h2>
            
            <p>Below is a selected list of my works (in <strong>chronological order</strong>), representative papers are <span style="background-color: #ffffd0;">highlighted</span>.</p>
          </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="mira_stop()" onmouseover="mira_start()"></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/hierarq_teaser.png' width="160" height="100">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://arxiv.org/abs/2412.07072"> -->
                <papertitle>Streaming Long-form Video Understanding With On-time Answering</papertitle>
              </a>
              <br>
              <strong> Shehreen Azad, </strong> Vibhav Vineet, Yogesh Rawat 
              <br>
              <em>Ongoing </em>
              <br>
              <!-- <a href="https://arxiv.org/abs/2412.07072">paper</a> &nbsp/&nbsp -->
              <!-- <a href="https://github.com/AKASH2907/stable-mean-teacher">code</a> -->
              <p></p>
              <p>
                Developing a novel memory-augmented framework for efficient streaming video understanding and proactive answering with Multimodal Large Language Models (MLLMs). 
              </p>
            </td>
          </tr>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/disenq_teaser.png' width="160" height="80">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2507.07262">
                <papertitle>DisenQ: Disentangling Q-Former for Activity-Biometrics</papertitle>
              </a>
              <br>
              <strong> Shehreen Azad, </strong> Yogesh Rawat
              <br>
              <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2025 <strong>Highlight</strong>
              <br>
              <em>Patent pending</em>
              <br>
              <a href="https://sacrcv.github.io/DisenQ-website/">Project Page</a> &nbsp/&nbsp
              <a href="https://arxiv.org/pdf/2507.07262">Paper</a>  &nbsp/&nbsp
              <p>
                Improved activity-aware person identification through a disentanglement based multimodal approach. 
              </p>
            </td>
          </tr>



        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->
          <tr onmouseout="mira_stop()" onmouseover="mira_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/hierarq_teaser.png' width="160" height="80">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2502.20678">
                <papertitle>HierarQ: Task-Aware Hierarchical Q-Former for Enhanced Video Understanding</papertitle>
              </a>
              <br>
              <strong> Shehreen Azad, </strong> Vibhav Vineet, Yogesh Rawat
              <br>
              <em>Computer Vision and Pattern Recognition Conference (<strong>CVPR</strong>)</em>, 2025
              <br>
              <a href="https://sacrcv.github.io/HierarQ-website/">Project Page</a> &nbsp/&nbsp
              <a href="https://arxiv.org/pdf/2502.20678">Paper</a>  &nbsp/&nbsp
              <p></p>
              <p>
                Developed a task-aware memory-augmented framework for efficient long-form video understanding. 
              </p>
            </td>
          </tr>






  </body>
</html>
